# git-ac Configuration File
# Copy this to ~/.config/git-ac.yaml and customize as needed

# Provider configuration - choose either "ollama" or "openai"
provider:
  type: "ollama"  # or "openai"
  timeout: 30s

  # Ollama configuration (when type: "ollama")
  ollama:
    host: "http://localhost:11434"
    model: "llama2"

  # OpenAI-compatible API configuration (when type: "openai")
  # openai:
  #   base_url: "https://api.openai.com/v1"
  #   api_key: "your-api-key-here"
  #   model: "gpt-4"

# Commit message configuration
commit:
  # Maximum length for commit subject line
  # Following conventional commit guidelines
  # Default: 72
  max_length: 72

# ============================================
# Example configurations:
# ============================================

# Ollama with different models:
# provider:
#   type: "ollama"
#   timeout: 60s
#   ollama:
#     host: "http://localhost:11434"
#     model: "codellama"  # or "mistral", "qwen3:4b", etc.

# OpenAI GPT-4:
# provider:
#   type: "openai"
#   timeout: 30s
#   openai:
#     base_url: "https://api.openai.com/v1"
#     api_key: "sk-your-key-here"
#     model: "gpt-4"

# Anthropic Claude (via OpenAI-compatible endpoint):
# provider:
#   type: "openai"
#   timeout: 30s
#   openai:
#     base_url: "https://api.anthropic.com/v1"
#     api_key: "your-anthropic-key"
#     model: "claude-3-sonnet-20240229"

# Local OpenAI-compatible server (e.g., LM Studio, vLLM):
# provider:
#   type: "openai"
#   timeout: 60s
#   openai:
#     base_url: "http://localhost:1234/v1"
#     api_key: "not-needed"  # or whatever your local server requires
#     model: "local-model"

# For shorter commit messages:
# commit:
#   max_length: 50
